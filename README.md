# ImageShap
CSCI 5922 Final Project: Combining LIME and SHAP to Generate More Interpretable SHAP Images

How important is a feature?
The answer is easy when asked of a linear model. In a linear model, each feature contributes to the output of the model in proportion to its value and the value of its assigned weight as in the linear function below.

<img src="https://github.com/lhayne/ImageShap/blob/master/docs/linearEquation.png" width="300" />

In a non-linear model, the question of feature importance becomes a little more difficult to answer. Shapley values provide an intuitive solution from game theory to measuring feature importance. Shapley values calculate the change in output of a "game" caused when a player is added to a game that already contains all subsets of other players. In this way, Shapley values effectively calculate feature importance, taking into account possible interaction effects between players. Below, the contribution of player A is calculated by subtracting how much the table earns without player A from the amount the table earns with them in all possible configurations.

<img src="https://github.com/lhayne/ImageShap/blob/master/docs/shap_payout.png" width="500" />

We can approximate Shapley values in the same way, by measuring the distance between outputs generated by the model with and without certain features. For convolutional networks we can generate a map of Shapley values for each pixel in the image.

Three methods are provided for generating shap maps:

# Shap Pixel 
        To approximate a shap pixel map, we do the following:
        1. Select a random sample from the dataset (Z)
        2. For each pixel
            i.  Select random pixels from Z and add them to a new image P
            ii. Fill in missing pixels in P using pixels from the example
            iii.Assesses the model's forward output for P with
                pixel of interest (phi_x)
            iv. Assesses the model's forward input for P without
                pixel of interest (phi_z)
            v.  Store in the feature map the difference between phi_x and phi_z
        3. Return the average shap value over all iterations for each pixel.
        
<img src="https://github.com/lhayne/ImageShap/blob/master/docs/mnist_epochs_shap_pixel.png" width="700" />

# Shap Superpixel
        To approximate a shap superpixel map, we do the following:
        1. Select a random sample from the dataset (Z)
        2. For each superpixel
            i.  Select random superpixels from Z and add them to a new image P
            ii. Fill in missing superpixels in P using superpixels from the example
            iii.Assesses the model's forward output for P with
                superpixel of interest (phi_x)
            iv. Assesses the model's forward input for P without
                superpixel of interest (phi_z)
            v.  Store in the feature map the difference between phi_x and phi_z
        3. Return the average shap value over all iterations for each pixel.
        
<img src="https://github.com/lhayne/ImageShap/blob/master/docs/mnist_superpixel.png" width="700" />

# Shap Cluster
        To approximate a shap cluster map, we do the following:
        1. Select a random sample from the dataset (Z)
        2. For each cluster
            i.  Select random cluster from Z and add them to a new image P
            ii. Fill in missing clusters in P using clusters from the example
            iii.Assesses the model's forward output for P with
                cluster of interest (phi_x)
            iv. Assesses the model's forward input for P without
                cluster of interest (phi_z)
            v.  Store in the feature map the difference between phi_x and phi_z
        3. Return the average shap value over all iterations for each pixel.
        
<img src="https://github.com/lhayne/ImageShap/blob/master/docs/catsdogs_cluster.png" width="700" />

# Getting Started
To get started simply clone the repository on your local machine. 

*MNIST Example*

The included mnist_example.py file trains a simple convolutional network on the mnist dataset.
Run the example:
```python
python mnist_example.py
```

*Cats and Dogs Example*

The included cats_dogs_example.py file trains a simple convolutional network on a dataset of cats and dogs. The images are (100 x 100) and the dataset contains 20,000 images (10,000 from each class).
Run the example:
```python
python mnist.py
```
